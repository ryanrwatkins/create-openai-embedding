! pip install openai
! pip install langchain
! pip install PyPDF2
! pip install pypdf
! pip install faiss-cpu


# If you are running this in Google Colab, then you can use files saved in your Google Drive for training the embedding file

from google.colab import drive
drive.mount('/content/drive')


from PyPDF2 import PdfReader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
import os
from PyPDF2 import PdfWriter
import glob
import pickle


os.environ["OPENAI_API_KEY"] = '<INSERT YOUR OPEN AI API KEY'

# Note: an embedding file create from about 1000 pages of PDF documents cost about $0.40 to build.

path = '/content/drive/MyDrive/<your folder with the PDF files to go into the embedding'
pdf_files = glob.glob(os.path.join(path, "*.pdf"))


# add all file in the list to the merger object

merger = PdfWriter()
for pdf in pdf_files:
  merger.append(pdf)
merger.write("merged-pdf.pdf")
merger.close()

# create smaller chunks of the merged file that will be used to create 

reader = PdfReader("merged-pdf.pdf")
raw_text = ''
for i, page in enumerate(reader.pages):
  text = page.extract_text()
  if text:
      raw_text += text
text_splitter = CharacterTextSplitter(        
  separator = "\n",
  chunk_size = 1000,
  chunk_overlap  = 200,
  length_function = len,
)
texts = text_splitter.split_text(raw_text)
len(texts)

# Use the OpenAI API to create the embedding and then use FAISS to prepare for similarity matching
# later, your ChatGPT chatbot will first identify the most similiar chunk (above, using cosine similarity) to your querry (below) and use that content as part of the responses.

embeddings = OpenAIEmbeddings()
docsearch = FAISS.from_texts(texts, embeddings)

# save as a Pickle file

with open("embeddings.pkl", "wb") as f:
    pickle.dump(docsearch, f)

# test the file to see results

query = str("<insert some querry relevant to your files>")
docs = docsearch.similarity_search(query)
print(docs)

# You do not have to use FAISS embedding, for example you can create a vector database as the embedding file, you can read the OpenAI and LangChain documentation to determine which is best for your project.

# To see how this works with a ChatGPT ChatBot, you can see the app and code at - https://huggingface.co/spaces/ryanrwatkins/needs
